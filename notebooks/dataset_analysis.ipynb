{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial dataset generation\n",
    "---\n",
    "We first setup constant values to load desired dataset from files generated with `distance_generator.py`.  \n",
    "Based on currently available options we can select following options:  \n",
    "- DATASET_TYPE: 'train' or 'test'\n",
    "- FEATURE: 'wasserstein_distance', 'rel_entr' or 'jensenshannon'\n",
    "- FEATURE_SELECTION: 'min' or 'max'\n",
    "- SEQUENCE_LENGTH: any number used in feautre genertion process\n",
    "  \n",
    "After gathering all required data paths, files are opened in a loop and payload is stored in a list. We also perform sample selection for final desired dataset. After process is finished files are saved to CSV format for further data exploration and ease of use in training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TYPE = [\"test\", \"train\"]\n",
    "FEATURE = [\"wasserstein_distance\", \"jensenshannon\"]\n",
    "FEATURE_SELECTION = [\"min\", \"max\"]\n",
    "SEQUENCE_LENGTH = [3, 5, 10]\n",
    "\n",
    "save_directory = \"../datasets/\"\n",
    "\n",
    "\n",
    "for dt in DATASET_TYPE:\n",
    "    fake_main_paths = glob.glob(f\"../../../DeepFake_Detection/wilddeep_results/fake_{dt}/*/fake/*\")\n",
    "    real_main_paths = glob.glob(f\"../../../DeepFake_Detection/wilddeep_results/real_{dt}/*/real/*\")\n",
    "    all_paths = fake_main_paths + real_main_paths\n",
    "    subsets = list()\n",
    "\n",
    "    for seql in SEQUENCE_LENGTH:\n",
    "        data_cache = {f\"{ft}\": {f\"{fts}\": list() for fts in FEATURE_SELECTION} for ft in FEATURE}\n",
    "            \n",
    "        for path in all_paths:\n",
    "            with open(path + \"/\" + f\"subsequence_data-{seql}.pkl\", 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            subsets.append(data)\n",
    "\n",
    "            for ft in FEATURE:\n",
    "                for fts in FEATURE_SELECTION:\n",
    "                    # Droping duplicates to account for cases where feature equals 0 for more than one subsequence\n",
    "                    if fts == \"min\":\n",
    "                        data_cache[ft][fts].append(data[data[ft] == data[ft].min()].drop_duplicates(subset=[ft]).reset_index(drop=True))\n",
    "\n",
    "                    elif fts == \"max\":\n",
    "                        data_cache[ft][fts].append(data[data[ft] == data[ft].max()].drop_duplicates(subset=[ft]).reset_index(drop=True))\n",
    "            \n",
    "                \n",
    "        full_dataset = pd.concat(subsets, axis=0)\n",
    "        full_dataset.to_csv(f\"{save_directory}{dt}_length-{seql}_full-dataset.csv\")\n",
    "\n",
    "        for ft in FEATURE:\n",
    "                for fts in FEATURE_SELECTION:\n",
    "                    final_dataset = pd.concat(data_cache[ft][fts], axis=0)\n",
    "                    final_dataset.to_csv(f\"{save_directory}{dt}_{ft}-{fts}_length-{seql}_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data exploration\n",
    "---\n",
    "In this section we will explore properties of WildDeepfake dataset based on available features. We start with descriptive analysis of each, previously mentioned feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset[\"path\"] = final_dataset.apply(lambda x: f\"{x['type']}_{x['subset']}/{x['video']}/{x['type']}/{x['sequence']}/{x['first_frame']}.png\", axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2e24267c165a1ce10e3342bdb7ba0ae1467706fe54c2e010f21b47024b1eb0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
