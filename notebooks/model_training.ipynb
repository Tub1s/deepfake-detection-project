{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Tuple, List, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), 'Physical GPUs,', len(logical_gpus), 'Logical GPUs')\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup\n",
    "DFDC_PATH = \"../../../DeepFake_Detection/DFDC_ALL_DATA_224/\"\n",
    "DFDC_METADATA = \"../../../DeepFake_Detection/DFDC_ALL_DATA/metadata/metadata.json\"\n",
    "WD_TRAIN_CSV_PATH = \"../datasets/train/min/train_wasserstein_distance-min_length-3_dataset.csv\"\n",
    "DATA_PATH = \"../../../DeepFake_Detection/WILDDEEP_DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_path_generator(csv_path: str, data_path: str) -> Tuple[List[List[str]], List[str]]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    X_paths, y = [], []\n",
    "    for i in range(len(df.index)):\n",
    "        subset = df.iloc[i].subset\n",
    "        video_type = df.iloc[i].type\n",
    "        video_number = df.iloc[i].video\n",
    "        sequence_number = df.iloc[i].sequence\n",
    "        first_frame = df.iloc[i].first_frame\n",
    "        subsequence_length = df.iloc[i].subsequence_length\n",
    "        \n",
    "        subsequence = []\n",
    "        for j in range(first_frame, first_frame + subsequence_length):\n",
    "            path =  data_path + f\"{subset}_{video_type}/\" + str(video_number) + \"/\" + video_type + \"/\" + str(sequence_number) + \"/\" + str(j) + \".png\"\n",
    "            subsequence.append(path)\n",
    "        \n",
    "        X_paths.append(subsequence)\n",
    "\n",
    "        y.append(\"0\" if video_type == \"real\" else \"1\")\n",
    "\n",
    "    return X_paths, y\n",
    "\n",
    "def ravel_and_match_lists(X: List[List], y: List) -> Tuple[List, List]:\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[i])):\n",
    "            x_out.append(X[i][j])\n",
    "            y_out.append(y[i])\n",
    "    \n",
    "\n",
    "    return x_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfdc_path(data_path: str, file: str) -> str:\n",
    "    path = data_path + file.replace(\".mp4\", \".jpg\")\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        raise Exception\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: At some point change to handle sequences of frames \n",
    "def load_dfdc_paths(metadata_path: str, data_path: str) -> Tuple[List[str], List[str]]:\n",
    "    X_paths, y = [], []\n",
    "    labels = [\"REAL\", \"FAKE\"]\n",
    "\n",
    "    dfdc_paths = pd.read_json(DFDC_METADATA)\n",
    "    dfdc_files = list(dfdc_paths.columns.values)\n",
    "\n",
    "    for file in tqdm(dfdc_files):\n",
    "        try:\n",
    "            X_paths.append(get_dfdc_path(data_path, file))\n",
    "            y.append(str(labels.index(dfdc_paths[file]['label'])))\n",
    "        except Exception as err:\n",
    "            #print(err)\n",
    "            pass\n",
    "    \n",
    "    return X_paths, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_lists(a: List, b: List, seed: int=0) -> Tuple[List, List]:\n",
    "    lists = list(zip(a, b))\n",
    "    random.seed(seed)\n",
    "    random.shuffle(lists)\n",
    "\n",
    "    a, b = zip(*lists)\n",
    "    a = list(a)\n",
    "    b = list(b)\n",
    "\n",
    "    return (a, b)\n",
    "\n",
    "def shuffle_arrays(a: np.ndarray, b: np.ndarray, seed: int=0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    np.random.seed(seed)\n",
    "    assert len(a) == len(b)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    return a[permutation], b[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: Add multi-feature resampling\n",
    "def resample_dataset(X: np.ndarray, y: np.ndarray, resampling_type: str, final_ratio: float, seed: int) -> Tuple[List, List]:\n",
    "    if resampling_type == \"undersample\":\n",
    "        sampler = RandomUnderSampler(sampling_strategy = final_ratio, random_state = seed)\n",
    "    elif resampling_type == \"oversample\":\n",
    "        sampler = RandomOverSampler(sampling_strategy = final_ratio, random_state = seed)\n",
    "    else:\n",
    "        raise Exception(\"Unknown resampling type. Available types: 'undersample', 'oversample'.\")\n",
    "    \n",
    "    X, y = sampler.fit_resample(X, y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119154/119154 [00:07<00:00, 16319.92it/s]\n"
     ]
    }
   ],
   "source": [
    "X_dfdc, y_dfdc = load_dfdc_paths(DFDC_METADATA, DFDC_PATH)\n",
    "X_dfdc, y_dfdc = np.array(X_dfdc), np.array(y_dfdc)\n",
    "X_dfdc, y_dfdc = X_dfdc.reshape(-1,1), y_dfdc.reshape(-1,1)\n",
    "\n",
    "X_wd_train, y_wd_train = custom_path_generator(WD_TRAIN_CSV_PATH, DATA_PATH)\n",
    "X_wd_train, y_wd_train = ravel_and_match_lists(X_wd_train, y_wd_train)\n",
    "X_wd_train, y_wd_train = shuffle_lists(X_wd_train, y_wd_train)\n",
    "X_wd_train, y_wd_train = np.array(X_wd_train), np.array(y_wd_train)\n",
    "X_wd_train, y_wd_train = X_wd_train.reshape(-1,1), y_wd_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((114344, 1), (114344, 1))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dfdc.shape, y_dfdc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37116, 1), (37116,))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dfdc, y_dfdc = resample_dataset(X_dfdc, y_dfdc, \"undersample\", 1, 1)\n",
    "X_dfdc.shape, y_dfdc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19518, 1), (19518, 1))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wd_train.shape, y_wd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25981, 1), (11135, 1))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dfdc_train, X_dfdc_test, y_dfdc_train, y_dfdc_test = train_test_split(X_dfdc, y_dfdc, test_size=0.3)\n",
    "X_dfdc_train.shape, X_dfdc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack([X_dfdc_train, X_wd_train])\n",
    "y_train = np.vstack([y_dfdc_train.reshape(-1,1), y_wd_train])\n",
    "\n",
    "X_train, y_train = shuffle_arrays(X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45499, 1), (45499, 1))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['../../../DeepFake_Detection/WILDDEEP_DATA/train_real/461/real/238/3232.png'],\n",
       "       ['../../../DeepFake_Detection/WILDDEEP_DATA/train_real/511/real/603/1604.png'],\n",
       "       ['../../../DeepFake_Detection/DFDC_ALL_DATA_224/ikkivspaft.jpg'],\n",
       "       ['../../../DeepFake_Detection/DFDC_ALL_DATA_224/rortwhsuas.jpg'],\n",
       "       ['../../../DeepFake_Detection/DFDC_ALL_DATA_224/npuplviqjf.jpg'],\n",
       "       ['../../../DeepFake_Detection/DFDC_ALL_DATA_224/jcjvaypgbq.jpg'],\n",
       "       ['../../../DeepFake_Detection/WILDDEEP_DATA/train_real/189/real/92/1235.png'],\n",
       "       ['../../../DeepFake_Detection/WILDDEEP_DATA/train_fake/498/fake/32/1152.png'],\n",
       "       ['../../../DeepFake_Detection/WILDDEEP_DATA/train_real/336/real/23/454.png'],\n",
       "       ['../../../DeepFake_Detection/DFDC_ALL_DATA_224/cgefriykjw.jpg']],\n",
       "      dtype='<U75')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0'],\n",
       "       ['0'],\n",
       "       ['0'],\n",
       "       ['1'],\n",
       "       ['1'],\n",
       "       ['0'],\n",
       "       ['0'],\n",
       "       ['1'],\n",
       "       ['0'],\n",
       "       ['0']], dtype='<U1')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2e24267c165a1ce10e3342bdb7ba0ae1467706fe54c2e010f21b47024b1eb0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
