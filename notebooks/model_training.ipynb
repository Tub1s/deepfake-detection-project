{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Tuple, List, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), 'Physical GPUs,', len(logical_gpus), 'Logical GPUs')\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup\n",
    "DFDC_PATH = \"../../../DeepFake_Detection/DFDC_ALL_DATA_224/\"\n",
    "DFDC_METADATA = \"../../../DeepFake_Detection/DFDC_ALL_DATA/metadata/metadata.json\"\n",
    "WD_TRAIN_CSV_PATH = \"../datasets/train/min/train_wasserstein_distance-min_length-3_dataset.csv\"\n",
    "DATA_PATH = \"../../../DeepFake_Detection/WILDDEEP_DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_path_generator(csv_path: str, data_path: str) -> Tuple[List[List[str]], List[str]]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    X_paths, y = [], []\n",
    "    for i in range(len(df.index)):\n",
    "        subset = df.iloc[i].subset\n",
    "        video_type = df.iloc[i].type\n",
    "        video_number = df.iloc[i].video\n",
    "        sequence_number = df.iloc[i].sequence\n",
    "        first_frame = df.iloc[i].first_frame\n",
    "        subsequence_length = df.iloc[i].subsequence_length\n",
    "        \n",
    "        subsequence = []\n",
    "        for j in range(first_frame, first_frame + subsequence_length):\n",
    "            path =  data_path + f\"{subset}_{video_type}/\" + str(video_number) + \"/\" + video_type + \"/\" + str(sequence_number) + \"/\" + str(j) + \".png\"\n",
    "            subsequence.append(path)\n",
    "        \n",
    "        X_paths.append(subsequence)\n",
    "\n",
    "        y.append(\"0\" if video_type == \"real\" else \"1\")\n",
    "\n",
    "    return X_paths, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfdc_path(data_path: str, file: str) -> str:\n",
    "    path = data_path + file.replace(\".mp4\", \".jpg\")\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        raise Exception\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: At some point change to handle sequences of frames \n",
    "def load_dfdc_paths(metadata_path: str, data_path: str) -> Tuple[List[str], List[str]]:\n",
    "    X_paths, y = [], []\n",
    "    labels = [\"REAL\", \"FAKE\"]\n",
    "\n",
    "    dfdc_paths = pd.read_json(DFDC_METADATA)\n",
    "    dfdc_files = list(dfdc_paths.columns.values)\n",
    "\n",
    "    for file in tqdm(dfdc_files):\n",
    "        try:\n",
    "            X_paths.append(get_dfdc_path(data_path, file))\n",
    "            y.append(str(labels.index(dfdc_paths[file]['label'])))\n",
    "        except Exception as err:\n",
    "            #print(err)\n",
    "            pass\n",
    "    \n",
    "    return X_paths, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_lists(a: List, b: List, seed: int=0) -> Tuple[List, List]:\n",
    "    lists = list(zip(a, b))\n",
    "    random.seed(seed)\n",
    "    random.shuffle(lists)\n",
    "\n",
    "    a, b = zip(*lists)\n",
    "    a = list(a)\n",
    "    b = list(b)\n",
    "\n",
    "    return (a, b)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dfdc, y_dfdc = load_dfdc_paths(DFDC_METADATA, DFDC_PATH)\n",
    "X_wd_train, y_wd_train = custom_path_generator(WD_TRAIN_CSV_PATH, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wd_train, y_wd_train = shuffle_lists(X_wd_train, y_wd_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2e24267c165a1ce10e3342bdb7ba0ae1467706fe54c2e010f21b47024b1eb0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
